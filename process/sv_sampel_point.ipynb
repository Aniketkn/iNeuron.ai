{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "there is no network: 1563\n",
      "there is no network: 1585\n",
      "there is no network: 1651\n",
      "there is no network: 1722\n",
      "there is no network: 1723\n",
      "there is no network: 1909\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import os\n",
    "import sv_setup_sample_analysis as sss\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "import json\n",
    "\n",
    "startTime = time.time()\n",
    "dirname = os.path.abspath(\"\")\n",
    "# change the json file location for every city\n",
    "jsonFile = \"./configuration/odense.json\"\n",
    "jsonPath = os.path.join(dirname, jsonFile)\n",
    "with open(jsonPath) as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "# read projected graphml\n",
    "graphmlProj_path = os.path.join(dirname, config[\"folder\"],\n",
    "                                config[\"graphmlProj_name\"])\n",
    "if os.path.isfile(graphmlProj_path):\n",
    "    G_proj = ox.load_graphml(graphmlProj_path)\n",
    "else:\n",
    "    # else read original graphml and reproject it\n",
    "    graphml_path = os.path.join(dirname, config[\"folder\"],\n",
    "                                config[\"graphmlName\"])\n",
    "    G = ox.load_graphml(graphml_path)\n",
    "    G_proj = ox.project_graph(G, to_crs=config[\"to_crs\"])\n",
    "    ox.save_graphml(G_proj,\n",
    "                    filename=config[\"graphmlProj_name\"],\n",
    "                    folder=os.path.join(dirname, config[\"folder\"]))\n",
    "\n",
    "# output gpkg for sample points to the same gpkg\n",
    "gpkgPath = os.path.join(dirname, config[\"folder\"], config[\"geopackagePath\"])\n",
    "hex250 = gpd.read_file(gpkgPath, layer=config[\"parametres\"][\"hex250\"])\n",
    "samplePointsData = gpd.read_file(gpkgPath,\n",
    "                                 layer=config[\"parametres\"][\"samplePoints\"])\n",
    "\n",
    "# get sample point dataframe columns\n",
    "samplePoint_column = samplePointsData.columns.tolist()\n",
    "samplePoint_column.append('index')\n",
    "\n",
    "# join id from hex to each sample point\n",
    "samplePointsData = gpd.sjoin(samplePointsData, hex250, how='left', op='within')\n",
    "samplePointsData = samplePointsData[samplePoint_column].copy()\n",
    "samplePointsData.rename(columns={'index': 'hex_id'}, inplace=True)\n",
    "\n",
    "print('begin to calculate average poplulation and intersection density.')\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# # method 1: apply method took 520s to process 530 sample points\n",
    "# # !!!!! change the argument 200 to 1600 for production\n",
    "# df_result = samplePointsData['geometry'].apply(sss.neigh_stats_apply,\n",
    "#                                                args=(\n",
    "#                                                    G_proj,\n",
    "#                                                    hex250,\n",
    "#                                                    1600,\n",
    "#                                                ))\n",
    "# # Concatenate the average of population and intersections back to the df of sample points\n",
    "# samplePointsData = pd.concat([samplePointsData, df_result], axis=1)\n",
    "# samplePointsData.to_file(gpkgPath,\n",
    "#                          layer='samplePointsData_temp',\n",
    "#                          driver='GPKG')\n",
    "\n",
    "# # method2: iterrows took 540s to process 530 sample points\n",
    "# # df_result = sss.neigh_stats_iterrows(samplePointsData, G_proj, hex250, 1600)\n",
    "\n",
    "# # method3: try to use vetorize in pandas(failed, may be not suitable)\n",
    "# # https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6\n",
    "# # df_result = sss.neigh_stats_apply(samplePointsData['geometry'],G_proj,hex250,200)\n",
    "\n",
    "# # method4: try to use rtree method in shapely to intersect(failed, only work when length is shorter.)\n",
    "# # https://stackoverflow.com/questions/14697442/faster-way-of-polygon-intersection-with-shapely\n",
    "# # https://geoffboeing.com/2016/10/r-tree-spatial-index-python/\n",
    "\n",
    "# method5: try to use multiprocessing, or GPU to calculate\n",
    "distance = config['parametres']['search_distance']\n",
    "pop_density = config['samplePoint_fieldNames']['sp_local_nh_avg_pop_density']\n",
    "intersection_density = config['samplePoint_fieldNames'][\n",
    "    'sp_local_nh_avg_intersection_density']\n",
    "\n",
    "\n",
    "def parallelize(data, func, num_of_processes=8):\n",
    "    data_split = np.array_split(data, num_of_processes)\n",
    "    pool = Pool(num_of_processes)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "\n",
    "def run_on_subset(func, data_subset):\n",
    "    return data_subset['geometry'].apply(func,\n",
    "                                         args=(G_proj, hex250, pop_density,\n",
    "                                               intersection_density, distance))\n",
    "\n",
    "\n",
    "def parallelize_on_rows(data, func, num_of_processes=8):\n",
    "    return parallelize(data, partial(run_on_subset, func), num_of_processes=8)\n",
    "\n",
    "\n",
    "df_result = parallelize_on_rows(samplePointsData, sss.neigh_stats_apply,\n",
    "                                cpu_count() - 1)\n",
    "\n",
    "samplePointsData = pd.concat([samplePointsData, df_result], axis=1)\n",
    "samplePointsData.to_file(gpkgPath,\n",
    "                         layer=config[\"parametres\"][\"tempLayer\"],\n",
    "                         driver='GPKG')\n",
    "#----------------------------------------------------------------------------\n",
    "print('The time to finish average pop and intersection density is: {}'.format(\n",
    "    time.time() - startTime))\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "print('begin to calculate assessbility to POIs.')\n",
    "#Calculate accessibility to POI(supermarket,convenience,pt,pso)\n",
    "# create the pandana network, just use nodes and edges\n",
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(G_proj)\n",
    "net = sss.create_pdna_net(gdf_nodes, gdf_edges)\n",
    "\n",
    "# get distance from \"destination\" layer\n",
    "gdf_poi1 = gpd.read_file(gpkgPath, layer=config[\"parametres\"][\"destinations\"])\n",
    "poi_names = [\n",
    "    config[\"parametres\"][\"supermarket\"], config[\"parametres\"][\"convenience\"],\n",
    "    config[\"parametres\"][\"PT\"]\n",
    "]\n",
    "distance = config[\"parametres\"][\"accessibility_distance\"]\n",
    "output_fieldNames1 = [\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_nearest_node_supermarket_dist\"],\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_nearest_node_convenience_dist\"],\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_nearest_node_pt_dist\"]\n",
    "]\n",
    "\n",
    "names1 = list(zip(poi_names, output_fieldNames1))\n",
    "\n",
    "gdf_poi_dist1 = sss.cal_dist2poi(gdf_poi1, distance, net, *(names1))\n",
    "\n",
    "# get distance from \"aos_nodes_30m_line\" layer\n",
    "gdf_poi2 = gpd.read_file(gpkgPath, layer=config[\"parametres\"][\"pos\"])\n",
    "\n",
    "names2 = [(config[\"parametres\"][\"pos\"],\n",
    "           config[\"samplePoint_fieldNames\"][\"sp_nearest_node_pos_dist\"])]\n",
    "# filterattr=False to indicate the layer is \"aos_nodes_30m_line\"\n",
    "gdf_poi_dist2 = sss.cal_dist2poi(gdf_poi2,\n",
    "                                 distance,\n",
    "                                 net,\n",
    "                                 *names2,\n",
    "                                 filterattr=False)\n",
    "\n",
    "gdf_nodes_poi_dist = pd.concat([gdf_nodes, gdf_poi_dist1, gdf_poi_dist2],\n",
    "                               axis=1)\n",
    "\n",
    "# convert distance of each nodes to binary index\n",
    "output_fieldNames1.append(\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_nearest_node_pos_dist\"])\n",
    "output_fieldNames2 = [\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_nearest_node_supermarket_binary\"],\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_nearest_node_convenience_binary\"],\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_nearest_node_pt_binary\"],\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_nearest_node_pos_binary\"]\n",
    "]\n",
    "names3 = list(zip(output_fieldNames1, output_fieldNames2))\n",
    "gdf_nodes_poi_dist = sss.convert2binary(gdf_nodes_poi_dist, *names3)\n",
    "# set index of gdf_nodes_poi_dist to use 'osmid' as index\n",
    "gdf_nodes_poi_dist.set_index('osmid', inplace=True, drop=False)\n",
    "\n",
    "# drop unuseful columns\n",
    "gdf_nodes_poi_dist.drop(['geometry', 'id', 'lat', 'lon', 'y', 'x', 'highway'],\n",
    "                        axis=1,\n",
    "                        inplace=True)\n",
    "\n",
    "# join the fields in the table of nodes table to the table of sample points\n",
    "# for each sample point, create a new field to save the osmid of  the closest point\n",
    "samplePointsData['closest_node_id'] = np.where(\n",
    "    samplePointsData.n1_distance <= samplePointsData.n2_distance,\n",
    "    samplePointsData.n1, samplePointsData.n2)\n",
    "\n",
    "# join the two tables based on node id (sample point, nodes: one to many)\n",
    "samplePointsData['closest_node_id'] = samplePointsData[\n",
    "    'closest_node_id'].astype(int)\n",
    "samplePointsData = samplePointsData.join(gdf_nodes_poi_dist,\n",
    "                                         on='closest_node_id',\n",
    "                                         how='left',\n",
    "                                         rsuffix='_nodes')\n",
    "\n",
    "# drop the nan rows samplePointsData, and deep copy to a new variable\n",
    "samplePointsData_withoutNan = samplePointsData.dropna().copy()\n",
    "nanData = samplePointsData[~samplePointsData.index.\n",
    "                           isin(samplePointsData_withoutNan.index)]\n",
    "nanData.to_file(gpkgPath, layer=config[\"parametres\"][\"dropNan\"], driver='GPKG')\n",
    "del nanData\n",
    "\n",
    "# create new field for living score,excluede public open space\n",
    "output_fieldNames2.pop()\n",
    "samplePointsData_withoutNan[\n",
    "    'sp_daily_living_score'] = samplePointsData_withoutNan[\n",
    "        output_fieldNames2].sum(axis=1)\n",
    "\n",
    "oriFieldNames = [\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_local_nh_avg_pop_density\"],\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_local_nh_avg_intersection_density\"],\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_daily_living_score\"]\n",
    "]\n",
    "newFieldNames = [\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_zscore_local_nh_avgpopdensity\"],\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_zscore_local_nh_avgintdensity\"],\n",
    "    config[\"samplePoint_fieldNames\"][\"sp_zscore_daily_living_score\"]\n",
    "]\n",
    "\n",
    "fieldNames = list(zip(oriFieldNames, newFieldNames))\n",
    "samplePointsData_withoutNan = sss.cal_zscores(samplePointsData_withoutNan,\n",
    "                                              fieldNames)\n",
    "\n",
    "# sum these three zscores for walkability\n",
    "samplePointsData_withoutNan[\n",
    "    'sp_walkability_index'] = samplePointsData_withoutNan[newFieldNames].sum(\n",
    "        axis=1)\n",
    "\n",
    "# change field names to the disired ones\n",
    "samplePointsData_withoutNan.rename(columns={'index': 'hex_id'}, inplace=True)\n",
    "\n",
    "samplePointsData_withoutNan.to_file(\n",
    "    gpkgPath, layer=config[\"parametres\"][\"samplepointResult\"], driver='GPKG')\n",
    "\n",
    "print('Total time is: {}'.format(time.time() - startTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
