{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['adelaide',\n",
    "'auckland',\n",
    "'baltimore',\n",
    "'bangkok',\n",
    "'barcelona',\n",
    "'belfast',\n",
    "'bern',\n",
    "'chennai',\n",
    "'mexico_city',\n",
    "'cologne',\n",
    "'ghent',\n",
    "'graz',\n",
    "'hanoi',\n",
    "'hong_kong',\n",
    "'lisbon',\n",
    "'melbourne',\n",
    "'odense',\n",
    "'olomouc',\n",
    "'sao_paulo',          \n",
    "'phoenix',\n",
    "'seattle',\n",
    "'sydney',\n",
    "'valencia',\n",
    "'vic'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_folder = '../../process'\n",
    "pop_col = [\"pop_ghs_2015\"]\n",
    "dest_col = [\"destinations\"]\n",
    "filenames_filepath = \"./filenames.csv\"\n",
    "np.random.seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start adelaide\n",
      "shape of dataframe for adelaide below\n",
      "(50, 28)\n",
      "start auckland\n",
      "shape of dataframe for auckland below\n",
      "(50, 28)\n",
      "start baltimore\n",
      "shape of dataframe for baltimore below\n",
      "(50, 28)\n",
      "start bangkok\n",
      "shape of dataframe for bangkok below\n",
      "(50, 28)\n",
      "start barcelona\n",
      "shape of dataframe for barcelona below\n",
      "(50, 28)\n",
      "start belfast\n",
      "shape of dataframe for belfast below\n",
      "(50, 28)\n",
      "start bern\n",
      "shape of dataframe for bern below\n",
      "(45, 28)\n",
      "start chennai\n",
      "shape of dataframe for chennai below\n",
      "(50, 28)\n",
      "start mexico_city\n",
      "shape of dataframe for mexico_city below\n",
      "(50, 28)\n",
      "start cologne\n",
      "shape of dataframe for cologne below\n",
      "(50, 28)\n",
      "start ghent\n",
      "shape of dataframe for ghent below\n",
      "(50, 28)\n",
      "start graz\n",
      "shape of dataframe for graz below\n",
      "(48, 27)\n",
      "start hanoi\n",
      "shape of dataframe for hanoi below\n",
      "(50, 28)\n",
      "start hong_kong\n",
      "shape of dataframe for hong_kong below\n",
      "(50, 28)\n",
      "start lisbon\n",
      "shape of dataframe for lisbon below\n",
      "(50, 28)\n",
      "start melbourne\n",
      "shape of dataframe for melbourne below\n",
      "(50, 28)\n",
      "start odense\n",
      "shape of dataframe for odense below\n",
      "(50, 27)\n",
      "start olomouc\n",
      "shape of dataframe for olomouc below\n",
      "(45, 28)\n",
      "start sao_paulo\n",
      "shape of dataframe for sao_paulo below\n",
      "(50, 28)\n",
      "start phoenix\n",
      "shape of dataframe for phoenix below\n",
      "(50, 28)\n",
      "start seattle\n",
      "shape of dataframe for seattle below\n",
      "(50, 28)\n",
      "start sydney\n",
      "shape of dataframe for sydney below\n",
      "(50, 28)\n",
      "start valencia\n",
      "shape of dataframe for valencia below\n",
      "(50, 28)\n",
      "start vic\n",
      "shape of dataframe for vic below\n",
      "(50, 27)\n"
     ]
    }
   ],
   "source": [
    "for city in cities:\n",
    "    \n",
    "    print(f\"start {city}\")\n",
    "    \n",
    "    # Access City-Specific Config\n",
    "    process_config_path = f\"../../process/configuration/{city}.json\"\n",
    "    \n",
    "    # Retrieve Data Paths\n",
    "    with open(process_config_path) as json_file:\n",
    "        config = json.load(json_file)\n",
    "\n",
    "    input_folder = os.path.join(process_folder, config['folder'])\n",
    "\n",
    "    gpkg_input = os.path.join(input_folder, config['geopackagePath'])\n",
    "    \n",
    "    # Extract Data\n",
    "    pop = gpd.read_file(gpkg_input, layer='pop_ghs_2015' )\n",
    "    \n",
    "    dests = gpd.read_file(gpkg_input, layer='destinations' )\n",
    "    \n",
    "    fresh_food = dests[dests['dest_name_full'].str.contains('Fresh Food / Market')]\n",
    "    \n",
    "    gdf_study_area = gpd.read_file(gpkg_input, layer=\"urban_study_region\")\n",
    "    study_area = gdf_study_area[\"geometry\"].iloc[0]\n",
    "\n",
    "    # Project Data\n",
    "    crs = gdf_study_area.crs\n",
    "    if pop.crs != crs:\n",
    "        pop = pop.to_crs(crs)\n",
    "    if fresh_food.crs != crs:\n",
    "        fresh_food = fresh_food.to_crs(crs)\n",
    "        \n",
    "    # Clip Data to Study Area\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", \"GeoSeries.notna\", UserWarning)  # temp warning suppression\n",
    "    pop_clipped = gpd.clip(pop, study_area)\n",
    "    fresh_food_clipped = gpd.clip(fresh_food, study_area)\n",
    "    \n",
    "    # Create Population Quantiles\n",
    "    pop_clipped['pop_quintile'] = pd.qcut(pop_clipped['pop_est'], 5, labels=False)\n",
    "    \n",
    "    # Join Pop Hexagons and Destinatinos\n",
    "    joined_freshfood = gpd.sjoin(fresh_food_clipped, pop_clipped, how='left', op='within')\n",
    "    \n",
    "    # Remove Values with No Fresh Food Destination\n",
    "    cleaned_joined_freshfood = joined_freshfood[~joined_freshfood['dest_name_full'].isnull()]\n",
    "    \n",
    "    q1_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 0].values.tolist()\n",
    "    q2_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 1].values.tolist()\n",
    "    q3_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 2].values.tolist()\n",
    "    q4_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 3].values.tolist()\n",
    "    q5_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 4].values.tolist()\n",
    "    \n",
    "    count = 0\n",
    "    good_quant = 0 \n",
    "    if len(q1_count_list) < 10:\n",
    "        q1_dests = len(q1_count_list)\n",
    "        count = count + len(q1_count_list)\n",
    "    else:\n",
    "        q1_dests = 10\n",
    "        count = count + 10\n",
    "        good_quant = good_quant + 1\n",
    "\n",
    "    if len(q2_count_list) < 10:\n",
    "        q2_dests = len(q2_count_list)\n",
    "        count = count + len(q2_count_list)\n",
    "    else:\n",
    "        q2_dests = 10\n",
    "        count = count + 10\n",
    "        good_quant = good_quant + 1\n",
    "\n",
    "    if len(q3_count_list) < 10:\n",
    "        q3_dests = len(q3_count_list)\n",
    "        count = count + len(q3_count_list)\n",
    "    else:\n",
    "        q3_dests = 10\n",
    "        count = count + 10\n",
    "        good_quant = good_quant + 1\n",
    "\n",
    "    if len(q4_count_list) < 10:\n",
    "        q4_dests = len(q4_count_list)\n",
    "        count = count + len(q4_count_list)\n",
    "    else:\n",
    "        q4_dests = 10\n",
    "        count = count + 10\n",
    "        good_quant = good_quant + 1\n",
    "\n",
    "    if len(q5_count_list) < 10:\n",
    "        q5_dests = len(q5_count_list)\n",
    "        count = count + len(q5_count_list)\n",
    "    else:\n",
    "        q5_dests = 10\n",
    "        count = count + 10\n",
    "        good_quant = good_quant + 1\n",
    "\n",
    "    extra_dests = 50 - count\n",
    "    extra_dests_per_quant = int(extra_dests / good_quant)\n",
    "\n",
    "    if extra_dests > 0:\n",
    "        count_2 = 0\n",
    "        good_quant_2 = 0 \n",
    "\n",
    "        if len(q1_count_list) < (10 + extra_dests_per_quant):\n",
    "            q1_dests = len(q1_count_list)\n",
    "            count_2 = count_2 + len(q1_count_list)\n",
    "        else:\n",
    "            q1_dests = 10 + extra_dests_per_quant\n",
    "            count_2 = count_2 + q1_dests\n",
    "            good_quant_2 = good_quant_2 + 1\n",
    "\n",
    "        if len(q2_count_list) < (10 + extra_dests_per_quant):\n",
    "            q2_dests = len(q2_count_list)\n",
    "            count_2 = count_2 + len(q2_count_list)\n",
    "        else:\n",
    "            q2_dests = 10 + extra_dests_per_quant\n",
    "            count_2 = count_2 + q2_dests\n",
    "            good_quant_2 = good_quant_2 + 1\n",
    "\n",
    "        if len(q3_count_list) < (10 + extra_dests_per_quant):\n",
    "            q3_dests = len(q3_count_list)\n",
    "            count_2 = count_2 + len(q3_count_list)\n",
    "        else:\n",
    "            q3_dests = 10 + extra_dests_per_quant\n",
    "            count_2 = count_2 + q3_dests\n",
    "            good_quant_2 = good_quant_2 + 1\n",
    "\n",
    "        if len(q4_count_list) < (10 + extra_dests_per_quant):\n",
    "            q4_dests = len(q4_count_list)\n",
    "            count_2 = count_2 + len(q4_count_list)\n",
    "        else:\n",
    "            q4_dests = 10 + extra_dests_per_quant\n",
    "            count_2 = count_2 + q4_dests\n",
    "            good_quant_2 = good_quant_2 + 1\n",
    "\n",
    "        if len(q5_count_list) < (10 + extra_dests_per_quant):\n",
    "            q5_dests = len(q5_count_list)\n",
    "            count_2 = count_2 + len(q5_count_list)\n",
    "        else:\n",
    "            q5_dests = 10 + extra_dests_per_quant + (extra_dests%good_quant)\n",
    "            count_2 = count_2 + q5_dests\n",
    "            good_quant_2 = good_quant_2 + 1\n",
    "        \n",
    "    q1_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 0]\n",
    "    q2_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 1]\n",
    "    q3_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 2]\n",
    "    q4_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 3]\n",
    "    q5_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 4]\n",
    "\n",
    "    q1_sample_dests = q1_count.sample(q1_dests)\n",
    "    q2_sample_dests = q2_count.sample(q2_dests)\n",
    "    q3_sample_dests = q3_count.sample(q3_dests)\n",
    "    q4_sample_dests = q4_count.sample(q4_dests)\n",
    "    q5_sample_dests = q5_count.sample(q5_dests)\n",
    "\n",
    "    sample_dests = [q1_sample_dests, q2_sample_dests, q3_sample_dests, q4_sample_dests, q5_sample_dests]\n",
    "\n",
    "    final_sample_dests = pd.concat(sample_dests)\n",
    "    \n",
    "    print(f\"shape of dataframe for {city} below\")\n",
    "    print(final_sample_dests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "    \n",
    "    print(f\"start {city}\")\n",
    "    \n",
    "    # Access City-Specific Config\n",
    "    process_config_path = f\"../../process/configuration/{city}.json\"\n",
    "    \n",
    "    # Retrieve Data Paths\n",
    "    with open(process_config_path) as json_file:\n",
    "        config = json.load(json_file)\n",
    "\n",
    "    input_folder = os.path.join(process_folder, config['folder'])\n",
    "\n",
    "    gpkg_input = os.path.join(input_folder, config['geopackagePath'])\n",
    "    \n",
    "    # Extract Data\n",
    "    pop = gpd.read_file(gpkg_input, layer='pop_ghs_2015' )\n",
    "    \n",
    "    dests = gpd.read_file(gpkg_input, layer='destinations' )\n",
    "    \n",
    "    fresh_food = dests[dests['dest_name_full'].str.contains('Fresh Food / Market')]\n",
    "    \n",
    "    gdf_study_area = gpd.read_file(gpkg_input, layer=\"urban_study_region\")\n",
    "    study_area = gdf_study_area[\"geometry\"].iloc[0]\n",
    "\n",
    "    # Project Data\n",
    "    crs = gdf_study_area.crs\n",
    "    if pop.crs != crs:\n",
    "        pop = pop.to_crs(crs)\n",
    "    if fresh_food.crs != crs:\n",
    "        fresh_food = fresh_food.to_crs(crs)\n",
    "        \n",
    "    # Clip Data to Study Area\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", \"GeoSeries.notna\", UserWarning)  # temp warning suppression\n",
    "    pop_clipped = gpd.clip(pop, study_area)\n",
    "    fresh_food_clipped = gpd.clip(fresh_food, study_area)\n",
    "    \n",
    "    # Create Population Quantiles\n",
    "    pop_clipped['pop_quintile'] = pd.qcut(pop_clipped['pop_est'], 5, labels=False)\n",
    "    \n",
    "    # Join Pop Hexagons and Destinatinos\n",
    "    joined_freshfood = gpd.sjoin(fresh_food_clipped, pop_clipped, how='left', op='within')\n",
    "    \n",
    "    # Remove Values with No Fresh Food Destination\n",
    "    cleaned_joined_freshfood = joined_freshfood[~joined_freshfood['dest_name_full'].isnull()]\n",
    "    \n",
    "    q1_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 0].values.tolist()\n",
    "    q2_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 1].values.tolist()\n",
    "    q3_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 2].values.tolist()\n",
    "    q4_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 3].values.tolist()\n",
    "    q5_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 4].values.tolist()\n",
    "    \n",
    "    count = 0\n",
    "    if len(q1_count_list) < 10:\n",
    "        q1_sampledeficit = 10 - len(q1_count_list)\n",
    "        if q1_sampledeficit % 4 == 0:\n",
    "            count = count\n",
    "        else:\n",
    "            count = count + (q1_sampledeficit % 4)\n",
    "        extra_q1 = (int(q1_sampledeficit/4))\n",
    "        q1_dests = len(q1_count_list) \n",
    "    else:\n",
    "        extra_q1 = 0\n",
    "        q1_dests = 10\n",
    "    if len(q2_count_list) < (extra_q1 + 10):\n",
    "        q2_sampledeficit = (extra_q1 + 10) - len(q2_count_list)\n",
    "        if q2_sampledeficit % 3 == 0:\n",
    "            count = count\n",
    "        else:\n",
    "            count = count +(q2_sampledeficit % 3)\n",
    "        extra_q2 = (int(q2_sampledeficit/3))\n",
    "        q2_dests = len(q2_count_list)\n",
    "    else:\n",
    "        extra_q2 = 0\n",
    "        q2_dests = 10 + extra_q1\n",
    "    if len(q3_count_list) < (extra_q1 + extra_q2 + 10):\n",
    "        q3_sampledeficit = (extra_q1 + extra_q2 + 10) - len(q3_count_list)\n",
    "        if q3_sampledeficit % 2 == 0:\n",
    "            count = count\n",
    "        else:\n",
    "            count = count + (q3_sampledeficit % 2)\n",
    "        extra_q3 = (int(q3_sampledeficit/2))\n",
    "        q3_dests = len(q3_count_list)\n",
    "    else:\n",
    "        extra_q3 = 0\n",
    "        q3_dests = 10 + extra_q1 + extra_q2\n",
    "    if len(q4_count_list) < (extra_q1 + extra_q2 + extra_q3 + 10):\n",
    "        q4_sampledeficit = (extra_q1 + extra_q2 + extra_q3 + 10) - len(q4_count_list)\n",
    "        extra_q4 = (int(q4_sampledeficit))\n",
    "        q4_dests = len(q4_count_list)\n",
    "    else:\n",
    "        extra_q4 = 0\n",
    "        q4_dests = 10 + extra_q1 + extra_q2 + extra_q3\n",
    "    if len(q5_count_list) < (extra_q1 + extra_q2 + extra_q3 + extra_q4 + 10):\n",
    "        print(\"fewer than 50 destinations exist\")\n",
    "    else:\n",
    "        q5_dests = 10 + extra_q1 + extra_q2 + extra_q3 + extra_q4 + count\n",
    "        \n",
    "    q1_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 0]\n",
    "    q2_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 1]\n",
    "    q3_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 2]\n",
    "    q4_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 3]\n",
    "    q5_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 4]\n",
    "\n",
    "    q1_sample_dests = q1_count.sample(q1_dests)\n",
    "    q2_sample_dests = q2_count.sample(q2_dests)\n",
    "    q3_sample_dests = q3_count.sample(q3_dests)\n",
    "    q4_sample_dests = q4_count.sample(q4_dests)\n",
    "    q5_sample_dests = q5_count.sample(q5_dests)\n",
    "\n",
    "    sample_dests = [q1_sample_dests, q2_sample_dests, q3_sample_dests, q4_sample_dests, q5_sample_dests]\n",
    "\n",
    "    final_sample_dests = pd.concat(sample_dests)\n",
    "    \n",
    "    print(f\"shape of dataframe for {city} below\")\n",
    "    print(final_sample_dests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {}\n",
    "for city in cities:\n",
    "    \n",
    "    print(f\"start {city}\")\n",
    "    \n",
    "    # Access City-Specific Config\n",
    "    process_config_path = f\"../../process/configuration/{city}.json\"\n",
    "    \n",
    "    # Retrieve Data Paths\n",
    "    with open(process_config_path) as json_file:\n",
    "        config = json.load(json_file)\n",
    "\n",
    "    input_folder = os.path.join(process_folder, config['folder'])\n",
    "\n",
    "    gpkg_input = os.path.join(input_folder, config['geopackagePath'])\n",
    "    \n",
    "    # Extract Data\n",
    "    pop = gpd.read_file(gpkg_input, layer='pop_ghs_2015' )\n",
    "    \n",
    "    dests = gpd.read_file(gpkg_input, layer='destinations' )\n",
    "    \n",
    "    fresh_food = dests[dests['dest_name_full'].str.contains('Fresh Food / Market')]\n",
    "    \n",
    "    gdf_study_area = gpd.read_file(gpkg_input, layer=\"urban_study_region\")\n",
    "    study_area = gdf_study_area[\"geometry\"].iloc[0]\n",
    "\n",
    "    # Project Data\n",
    "    crs = gdf_study_area.crs\n",
    "    if pop.crs != crs:\n",
    "        pop = pop.to_crs(crs)\n",
    "    if fresh_food.crs != crs:\n",
    "        fresh_food = fresh_food.to_crs(crs)\n",
    "        \n",
    "    # Clip Data to Study Area\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", \"GeoSeries.notna\", UserWarning)  # temp warning suppression\n",
    "    pop_clipped = gpd.clip(pop, study_area)\n",
    "    fresh_food_clipped = gpd.clip(fresh_food, study_area)\n",
    "    \n",
    "    # Create Population Quantiles\n",
    "    pop_clipped['pop_quintile'] = pd.qcut(pop_clipped['pop_est'], 5, labels=False)\n",
    "    \n",
    "    # Join Pop Hexagons and Destinatinos\n",
    "    joined_freshfood = gpd.sjoin(fresh_food_clipped, pop_clipped, how='left', op='within')\n",
    "    \n",
    "    # Remove Values with No Fresh Food Destination\n",
    "    cleaned_joined_freshfood = joined_freshfood[~joined_freshfood['dest_name_full'].isnull()]\n",
    "    \n",
    "    q1_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 0].values.tolist()\n",
    "    q2_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 1].values.tolist()\n",
    "    q3_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 2].values.tolist()\n",
    "    q4_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 3].values.tolist()\n",
    "    q5_count_list = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 4].values.tolist()\n",
    "    \n",
    "    count = 0\n",
    "    if len(q1_count_list) < 10:\n",
    "        q1_sampledeficit = 10 - len(q1_count_list)\n",
    "        if q1_sampledeficit % 4 == 0:\n",
    "            count = count\n",
    "        else:\n",
    "            count = count + (q1_sampledeficit % 4)\n",
    "        extra_q1 = (int(q1_sampledeficit/4))\n",
    "        q1_dests = len(q1_count_list) \n",
    "    else:\n",
    "        extra_q1 = 0\n",
    "        q1_dests = 10\n",
    "    if len(q2_count_list) < (extra_q1 + 10):\n",
    "        q2_sampledeficit = (extra_q1 + 10) - len(q2_count_list)\n",
    "        if q2_sampledeficit % 3 == 0:\n",
    "            count = count\n",
    "        else:\n",
    "            count = count +(q2_sampledeficit % 3)\n",
    "        extra_q2 = (int(q2_sampledeficit/3))\n",
    "        q2_dests = len(q2_count_list)\n",
    "    else:\n",
    "        extra_q2 = 0\n",
    "        q2_dests = 10 + extra_q1\n",
    "    if len(q3_count_list) < (extra_q1 + extra_q2 + 10):\n",
    "        q3_sampledeficit = (extra_q1 + extra_q2 + 10) - len(q3_count_list)\n",
    "        if q3_sampledeficit % 2 == 0:\n",
    "            count = count\n",
    "        else:\n",
    "            count = count + (q3_sampledeficit % 2)\n",
    "        extra_q3 = (int(q3_sampledeficit/2))\n",
    "        q3_dests = len(q3_count_list)\n",
    "    else:\n",
    "        extra_q3 = 0\n",
    "        q3_dests = 10 + extra_q1 + extra_q2\n",
    "    if len(q4_count_list) < (extra_q1 + extra_q2 + extra_q3 + 10):\n",
    "        q4_sampledeficit = (extra_q1 + extra_q2 + extra_q3 + 10) - len(q4_count_list)\n",
    "        extra_q4 = (int(q4_sampledeficit))\n",
    "        q4_dests = len(q4_count_list)\n",
    "    else:\n",
    "        extra_q4 = 0\n",
    "        q4_dests = 10 + extra_q1 + extra_q2 + extra_q3\n",
    "    if len(q5_count_list) < (extra_q1 + extra_q2 + extra_q3 + extra_q4 + 10):\n",
    "        print(\"fewer than 50 destinations exist\")\n",
    "    else:\n",
    "        q5_dests = 10 + extra_q1 + extra_q2 + extra_q3 + extra_q4 + count\n",
    "        \n",
    "    q1_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 0]\n",
    "    q2_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 1]\n",
    "    q3_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 2]\n",
    "    q4_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 3]\n",
    "    q5_count = cleaned_joined_freshfood.loc[cleaned_joined_freshfood['pop_quintile'] == 4]\n",
    "\n",
    "    q1_sample_dests = q1_count.sample(q1_dests)\n",
    "    q2_sample_dests = q2_count.sample(q2_dests)\n",
    "    q3_sample_dests = q3_count.sample(q3_dests)\n",
    "    q4_sample_dests = q4_count.sample(q4_dests)\n",
    "    q5_sample_dests = q5_count.sample(q5_dests)\n",
    "\n",
    "    sample_dests = [q1_sample_dests, q2_sample_dests, q3_sample_dests, q4_sample_dests, q5_sample_dests]\n",
    "\n",
    "    final_sample_dests = pd.concat(sample_dests)\n",
    "    \n",
    "    final_sample_dests = final_sample_dests.to_crs({'init': 'epsg:4326'})\n",
    "    \n",
    "    final_sample_dests['lat'] = final_sample_dests.geometry.y\n",
    "    final_sample_dests['lon'] = final_sample_dests.geometry.x\n",
    "    \n",
    "    # Create Excel\n",
    "    \n",
    "    print(ox.ts(), f\"add {city} to excel\")\n",
    "    destination = {}\n",
    "    \n",
    "    for dest in final_sample_dests:\n",
    "        city_name = {city}\n",
    "        hexagon_pop_quantile = final_sample_dests['pop_quintile']\n",
    "        latitude = final_sample_dests['lat']\n",
    "        longitude = final_sample_dests['lon']\n",
    "        google_maps_screenshot = f\"{latitude}_{longitude}_{city}_google_maps_image\"\n",
    "        google_satellite_screenshot = f\"{latitude}_{longitude}_{city}_google_satellite_image\"\n",
    "        google_street_view_screenshot = f\"{latitude}_{longitude}_{city}_google_streetview_image\"\n",
    "\n",
    "        # calculate total street length and edge count in each dataset, then add to indicators\n",
    "        filenames[destination][\"City_Name\"] = city_name\n",
    "        filenames[destination][\"Hexagon_Pop_Quintile\"] = hexagon_pop_quantile\n",
    "        filenames[destination][\"Latitude\"] = latitude\n",
    "        filenames[destination][\"Longitude\"] = longitude\n",
    "        filenames[destination][\"Google_Maps_Date\"] = \"\"\n",
    "        filenames[destination][\"Google_Maps_Screenshot\"] = google_maps_screenshot\n",
    "        filenames[destination][\"Google_Satellite_Date\"] = \"\"\n",
    "        filenames[destination][\"Google_Satellite_Screenshot\"] = google_satellite_screenshot\n",
    "        filenames[destination][\"Google_Street_View_Date\"] = \"\"\n",
    "        filenames[destination][\"Google_Street_View_Screenshot\"] = google_street_view_screenshot\n",
    "        filenames[destination][\"Assessment\"] = \"\"\n",
    "        print(ox.ts(), f\"finshed names for {city}\")\n",
    "\n",
    "# turn indicators into a dataframe and save to disk\n",
    "df_filenames = pd.DataFrame(filenames).T\n",
    "df_filenames.to_csv(filenames_filepath, index=True, encoding=\"utf-8\")\n",
    "print(ox.ts(), f'all done, saved filenames to disk at \"{filenames_filepath}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GlobalInd)",
   "language": "python",
   "name": "globalind"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
